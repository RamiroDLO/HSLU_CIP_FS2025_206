---
title: "AutoCommodity Insights"
subtitle: "Analyzing the Relationship Between Used Car Prices"
author: "Group 206 — Dongyuan Gao, Ramiro Diez-Liebana, Cyriel Van Helleputte"
date: "November 2025"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

<div style="text-align: center; font-size: 1.05em;">
<em>Powered by Autoscout24 Scraper & Yahoo Finance API</em>
</div>

```{=latex}
\vspace{8pt}
```

**Group 206**

```{=latex}
\vspace{4pt}
```

*Dongyuan Gao · Ramiro Diez-Liebana · Cyriel Van Helleputte*

```{=latex}
\vspace{12pt}\hrule\vspace{12pt}
```

```{=latex}
\newpage
```

## Project Overview

### Driving Smarter Decisions in the Swiss Used Car Market

#### The Storyline (Potential Business Problem)
The Swiss used car market is highly competitive. Our **fictional client** AutoHelvetia AG, a leading national **used car dealer**, faces the challenge of optimizing their pricing & purchasing strategy. In recent years, commodity prices are volatile and affects pricing of cars.

#### Our Solution
This project delivers an **advanced data collection** and **anylsis** framework. Our goal is to collect valuable **market data** and uncover relationships between used car prices and key commodity markets. We develop a tool box using **web scraping of AutoScout24.ch** and integrating with **Yahoo Finance commodity data**, to provide AutoHelvetia AG data-driven insights for:

- **Optimize Pricing Strategies**
- **Gain Competitive Advantage**

#### Project Structure
```
project_scraping_CIP_analysis_car_commodity_price/
├── Analysis/                # Analysis notebooks and scripts
│   ├── RQ1/                 # Research Question 1 script & analysis
│   ├── RQ2/                 # Research Question 2 script & analysis
│   └── RQ3/                 # Research Question 3 script & analysis
├── Data/                    # Data storage
│   ├── API_data_pull/       # API-fetched commodity data & script
│   ├── clean_data/          # Processed and cleaned datasets & script
│   └── Scraping/            # Web scraped data and scripts & scraper script
├── Documentation.md         # This documentation file
└── README.md                # Project overview
```


## Feasibility Research

### Ethical Feasibility of Web Scraping AutoScout24.ch

This web scraping project was evaluated for both technical and legal feasibility. We focused on the academic research context and our analysis of AutoScout24.ch's robots.txt file and terms of service indicates that the project operates within acceptable boundaries for academic research purposes.
- **robots.txt Analysis**:
  - Allowed: General listing pages without filters
  - Restricted: User account pages (`/de/account/`, `/de/member/`)
  - Restricted: Filtered search results with specific URL parameters (e.g., `sort=`, `pricefrom=`)
  - Restricted: Administrative functions

#### Technical Feasibility
- **Data Extraction**: Ethically extracts vehicle specifications, pricing, and listing details with Scraper and Yahoo Finance API, involving selenium and beautifulsoup.
- **Data Availability**: We found consistent and abundant data, which is appropriate for analysis for both used car listings and Commodity Data

#### Analytical Feasibility
- **Statistical Methods**: Appropriate statistical methods can be appllied for analysis, including correlation analysis, regression analysis, and time series analysis, etc.
- **Potential Conclusions**: The project can provide potential valuable insights into the relationship between used car prices and commodity prices, helping stakeholders make informed decisions


## Data Collection

### Web Scraping
[Document the web scraping process, including:
- Target websites
- Scraping methodology
- Data points collected
- Frequency of updates]

### API Integration
[Document the API integration, including:
- APIs used (Yahoo Finance, etc.)
- Authentication process
- Data retrieval methods
- Rate limits and handling]

## Data Processing
[Document the data processing pipeline, including:
- Data cleaning steps
- Data transformation
- Handling missing values
- Data validation]

## Analysis and Methodology

### Research Questions
1. [Research Question 1]
2. [Research Question 2]
3. [Research Question 3]

### Methodology
[Describe the analytical methods used, including:
- Statistical methods
- Machine learning models (if any)
- Validation techniques]

## Results and Findings
[Present key findings, including:
- Summary statistics
- Visualizations
- Key insights
- Limitations]

## Conclusion and Future Work
[Provide conclusions and potential future improvements]

## References
[List all references and data sources]

## Appendices
### A. Data Dictionary
[Document the structure and meaning of all data fields]

### B. Troubleshooting
[Common issues and solutions]

### C. Contributing
[Guidelines for contributing to the project]
