---
title: "AutoCommodity Insights"
subtitle: "Analyzing the Relationship Between Used Car Prices"
author: "Group 206 — Dongyuan Gao, Ramiro Diez-Liebana, Cyriel Van Helleputte"
date: "November 2025"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

<div style="text-align: center; font-size: 1.05em;">
<em>Powered by Autoscout24 Scraper & Yahoo Finance API</em>
</div>

```{=latex}
\vspace{8pt}
```

**Group 206**

```{=latex}
\vspace{4pt}
```

*Dongyuan Gao · Ramiro Diez-Liebana · Cyriel Van Helleputte*

```{=latex}
\vspace{12pt}\hrule\vspace{12pt}
```

```{=latex}
\newpage
```

## Project Overview
[Provide a brief overview of the project, its objectives, and its significance.]

## Feasibility Research

## Project Structure
```
project_scraping_CIP_analysis_car_commodity_price/
├── Analysis/                # Analysis notebooks and scripts
│   ├── RQ1/                 # Research Question 1 script & analysis
│   ├── RQ2/                 # Research Question 2 script & analysis
│   └── RQ3/                 # Research Question 3 script & analysis
├── Data/                    # Data storage
│   ├── API_data_pull/       # API-fetched commodity data & script
│   ├── clean_data/          # Processed and cleaned datasets & script
│   └── Scraping/            # Web scraped data and scripts & scraper script
├── Documentation.md         # This documentation file
└── README.md                # Project overview
```

## Setup and Installation
[Provide installation instructions, including:
- Python version requirements
- Required packages (with versions)
- Environment setup
- Configuration needed]

## Data Collection

### Web Scraping
[Document the web scraping process, including:
- Target websites
- Scraping methodology
- Data points collected
- Frequency of updates]

### API Integration
[Document the API integration, including:
- APIs used (Yahoo Finance, etc.)
- Authentication process
- Data retrieval methods
- Rate limits and handling]

## Data Processing
[Document the data processing pipeline, including:
- Data cleaning steps
- Data transformation
- Handling missing values
- Data validation]

## Analysis and Methodology

### Research Questions
1. [Research Question 1]
2. [Research Question 2]
3. [Research Question 3]

### Methodology
[Describe the analytical methods used, including:
- Statistical methods
- Machine learning models (if any)
- Validation techniques]

## Results and Findings
[Present key findings, including:
- Summary statistics
- Visualizations
- Key insights
- Limitations]

## Conclusion and Future Work
[Provide conclusions and potential future improvements]

## References
[List all references and data sources]

## Appendices
### A. Data Dictionary
[Document the structure and meaning of all data fields]

### B. Troubleshooting
[Common issues and solutions]

### C. Contributing
[Guidelines for contributing to the project]
